# -*- coding: utf-8 -*-
"""Handling missing values

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H3rtxYLrZg7q8LvxOnwCTUmOyr43XUOX
"""



"""## **Handling Missing Values – Ames Housing Dataset (Regression)**

"""

from google.colab import drive
drive.mount('/content/drive')

data_path = "/content/drive/MyDrive/0.Latest_DS_Course/Projects/EDA/AmesHousing.csv"

"""### **1. Setup**"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.impute import KNNImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

# Create folder for processed data
os.makedirs("processed", exist_ok=True)

# Load dataset
df = pd.read_csv("/content/AmesHousing (1).csv")

df.shape

df.info()

"""
### **2. Missingness Exploration**
"""

# Counts and percentages
missing_counts = df.isna().sum()
missing_perc = (missing_counts / len(df)) * 100
missing_summary = pd.DataFrame({"Missing Count": missing_counts, "Missing %": missing_perc})
missing_summary = missing_summary[missing_summary["Missing Count"] > 0].sort_values("Missing %", ascending=False)

display(missing_summary)

# Visuals
msno.matrix(df)
plt.show()

msno.bar(df)
plt.show()

missing_summary.shape

"""
### **3. Techniques Implemented**

"""

results = []

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

def evaluate_and_save(df_processed, code, description):
    X = df_processed.drop(columns=["SalePrice"])
    y = df_processed["SalePrice"]

    # Fill missing values (numeric with 0, categorical with "Unknown")
    for col in X.select_dtypes(include=['number']):
        X[col] = X[col].fillna(0)
    for col in X.select_dtypes(exclude=['number']):
        X[col] = X[col].fillna("Unknown")

    # One-hot encode categorical variables
    X = pd.get_dummies(X, drop_first=True)

    # Train/test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Model training
    model = LinearRegression()
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)

    # Metrics
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    # Store results
    results.append({
        "Code": code,
        "Technique": description,
        "RMSE": rmse,
        "R2": r2
    })

    # Save processed dataset
    df_processed.to_csv(f"processed/{code}.csv", index=False)

"""
#### **T1 – Drop rows with missing values**
"""

# df_t1 = df.dropna()
# evaluate_and_save(df_t1, "T1", "Drop rows with missing values")

# #this fails because all the rows deleted

# understand this formula

# df_t1 = df.dropna(thresh=int((1-0.7) * len(df)), axis=1)
# this statement will drop columns with more than 70% missing values

# correct way to read this statement is : keep columns that have atleast 30% non missing value, any less drop it

# Drop columns with >70% missing
df_t1 = df.dropna(thresh=int((1-0.7) * len(df)), axis=1)
# Now drop rows that still have missing values
df_t1 = df_t1.dropna()
evaluate_and_save(df_t1, "T1", "Drop rows after removing sparse columns")

df_t1

"""
#### **T2 – Drop columns with >70% missing**
"""

threshold = 0.7
df_t2 = df.dropna(thresh=int((1-threshold) * len(df)), axis=1)
df_t2 = df_t2.fillna(0)
evaluate_and_save(df_t2, "T2", "Drop columns with >70% missing")

"""
#### **T3 – Fill with constant**
"""

df_t3 = df.copy()
for col in df_t3:
    if df_t3[col].dtype == "object":
        df_t3[col] = df_t3[col].fillna("Unknown")
    else:
        df_t3[col] = df_t3[col].fillna(0)
evaluate_and_save(df_t3, "T3", "Fill with constants")

"""
#### **T4 – Mean (numeric) + Mode (categorical)**
"""

df_t4 = df.copy()
for col in df_t4:
    if df_t4[col].dtype == "object":
        df_t4[col] = df_t4[col].fillna(df_t4[col].mode()[0])
    else:
        df_t4[col] = df_t4[col].fillna(df_t4[col].mean())
evaluate_and_save(df_t4, "T4", "Mean numeric + Mode categorical")

"""
#### **T5 – Median (numeric) + Mode (categorical)**




"""

df_t5 = df.copy()
for col in df_t5:
    if df_t5[col].dtype == "object":
        df_t5[col] = df_t5[col].fillna(df_t5[col].mode()[0])
    else:
        df_t5[col] = df_t5[col].fillna(df_t5[col].median())
evaluate_and_save(df_t5, "T5", "Median numeric + Mode categorical")

"""#### **T6 – KNN Imputation**


"""

df_t6 = pd.get_dummies(df, drop_first=True)
imputer = KNNImputer(n_neighbors=5)
df_t6 = pd.DataFrame(imputer.fit_transform(df_t6), columns=df_t6.columns)
evaluate_and_save(df_t6, "T6", "KNN Imputation")

"""#### **T7 – Iterative Imputation (MICE)**

"""

df_t7 = pd.get_dummies(df, drop_first=True)
imputer = IterativeImputer(random_state=42)
df_t7 = pd.DataFrame(imputer.fit_transform(df_t7), columns=df_t7.columns)
evaluate_and_save(df_t7, "T7", "MICE Imputation")

"""#### **T8 – Domain-based Alley Imputation**


"""

df_t8 = df.copy()
df_t8["Alley"] = df_t8["Alley"].fillna("NoAlley")
evaluate_and_save(df_t8, "T8", "Domain-based Alley fill")

"""
#### **T9 – Add Missingness Indicators**
"""

df_t9 = df.copy()
for col in df_t9.columns:
    df_t9[col+"_was_missing"] = df_t9[col].isna().astype(int)
    if df_t9[col].dtype == "object":
        df_t9[col] = df_t9[col].fillna("Unknown")
    else:
        df_t9[col] = df_t9[col].fillna(df_t9[col].median())
evaluate_and_save(df_t9, "T9", "Missingness Indicators + Imputation")

df_t9.shape

"""### **4. Model Evaluation Summary**


"""

results_df = pd.DataFrame(results)
print(results_df)
results_df.to_csv("processed/ames_imputation_summary.csv", index=False)

"""### **5. Visual Comparison**




"""

sns.barplot(data=results_df, x="Code", y="RMSE")
plt.title("RMSE by Missing Value Handling Technique (Lower is Better)")
plt.show()

sns.barplot(data=results_df, x="Code", y="R2")
plt.title("Rsquare vs technique(Higher is better)")
plt.show()

